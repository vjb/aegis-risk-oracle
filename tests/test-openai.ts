#!/usr/bin/env bun
/**
 * Simple OpenAI Test Script
 * Usage: bun run test-openai.ts "Your question here"
 * Or interactive: bun run test-openai.ts
 */

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || Bun.env.OPENAI_API_KEY;

if (!OPENAI_API_KEY) {
    console.error("‚ùå OPENAI_API_KEY not found in environment");
    console.error("   Set it with: $env:OPENAI_API_KEY = 'sk-...'");
    process.exit(1);
}

const MODEL = "gpt-4o-mini"; // Same model used in Aegis workflow

async function askOpenAI(question: string): Promise<void> {
    console.log(`\nü§ñ Model: ${MODEL}`);
    console.log(`üìù Question: ${question}\n`);
    console.log("‚îÅ".repeat(60));

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
            model: MODEL,
            messages: [
                { role: "user", content: question }
            ],
            max_tokens: 500
        })
    });

    if (!response.ok) {
        const error = await response.text();
        console.error(`‚ùå API Error (${response.status}): ${error}`);
        process.exit(1);
    }

    const data = await response.json() as any;

    console.log(`\nüí¨ Response:\n`);
    console.log(data.choices[0].message.content);
    console.log("\n" + "‚îÅ".repeat(60));
    console.log(`üìä Model used: ${data.model}`);
    console.log(`üî¢ Tokens: ${data.usage?.prompt_tokens} input, ${data.usage?.completion_tokens} output`);
}

// Get question from command line args or use default
const question = process.argv.slice(2).join(" ") || "What model are you? Please state your exact model identifier.";

askOpenAI(question).catch(console.error);
